{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5b2b9b7",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "### 배경\n",
    "\n",
    "    - 데이터 타입에 상관없이 특정 데이터 입력 시 자동으로 모델을 선정하고 성능을 평가하여 결과를 제시해 주는 autoML 역량 내재화를 목적으로 합니다.\n",
    "\n",
    "### 사용 가능 데이터\n",
    "\n",
    "    - 우선, table data에 대한 분석만 가능하도록 만들었으며, 추후 다양한 데이터에 대해 적용이 가능하도록 업데이트할 예정입니다.\n",
    "    \n",
    "    - Pycaret, autokeras, Deep Learning 모델을 활용하며, 해당 모델을 구성하였습니다.\n",
    "    \n",
    "\n",
    "### 모델 사용 환경 및 세팅\n",
    "\n",
    "    DataFrame Input\n",
    "\n",
    "    target 변수는 마지막 column에 배치\n",
    "\n",
    "    scikit-learn version 0.23.2\n",
    "\n",
    "    tensorflow 2.5\n",
    "\n",
    "    python 3.8 사용\n",
    "\n",
    "    pycaret, autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "397aa398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from tensorflow import keras\n",
    "import pycaret\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import autokeras as ak\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import scikitplot as skplt\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd53815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f4e35279",
   "metadata": {},
   "outputs": [],
   "source": [
    "class classification_model():\n",
    "    \n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "        \n",
    "    def preprocess(self):\n",
    "        target_name = self.df.columns[-1]\n",
    "        \n",
    "        \n",
    "        # 학습에 사용될 dataset에 대한 transforamtion 진행 / 이 중 20% 를 test set 으로 사용하며 이는 학습에 사용되지 않는\n",
    "        # holdout set에 해당\n",
    "        self.exp_clf = setup(data = self.df, target = target_name, transformation = True, normalize = True,\n",
    "                       session_id=123, log_experiment=True, experiment_name='classification', fold_shuffle=True,\n",
    "                       imputation_type='iterative', train_size = 0.8)\n",
    "        \n",
    "        # train / test size 를 출력\n",
    "        self.X_train = self.exp_clf[5][1][1]\n",
    "        self.y_train = self.exp_clf[5][2][1]\n",
    "        self.X_test = self.exp_clf[5][3][1]\n",
    "        self.y_test = self.exp_clf[5][4][1]\n",
    "        print('X_train_shape : ', self.X_train.shape)\n",
    "        print('y_train_shape : ', self.y_train.shape)\n",
    "        print('X_test_shape : ', self.X_test.shape)\n",
    "        print('y_test_shape : ', self.y_test.shape)\n",
    "        \n",
    "        \n",
    "    def pycaret_compare_models(self):\n",
    "        '''\n",
    "        pycaret 오픈 소스를 통한 모델 생성 및 비교\n",
    "        \n",
    "        accuracy 기준으로 10개 fold를 이용해 cross validation 성능이 가장 좋은 top 3 모델을 선정\n",
    "        \n",
    "        총 5개의 후보에 대해 비교 진행\n",
    "        1. 가장 성능이 좋은 것으로 나타난 머신러닝 모델\n",
    "        2. top 3 모델을 blending한 모델 (hard)\n",
    "        3. top 3 모델을 blending한 모델 (hard X)\n",
    "        4. top 3 모델을 stacking한 모델\n",
    "        5. top 3 모델을 xgboost를 이용해 stacking한 모델\n",
    "        \n",
    "        총 5가지 모델 중 accuracy가 가장 좋은 모델을 선정 및 결과 도출\n",
    "        '''\n",
    "        exp_clf = self.exp_clf\n",
    "        top3 = compare_models(n_select=3)\n",
    "        \n",
    "        # 가장 성능이 좋은 모델 tuning\n",
    "        m1 = create_model(top3[0])\n",
    "        tuned_model1 = tune_model(m1)\n",
    "        \n",
    "        m2 = create_model(top3[1])\n",
    "        m3 = create_model(top3[2])\n",
    "        \n",
    "        # 가장 성능이 좋은 3개의 모델 blend\n",
    "        blend_hard = blend_models(estimator_list = [m1, m2, m3], method='hard')\n",
    "        blender_top3 = blend_models(top3)\n",
    "        \n",
    "        # 가장 성능이 좋은 3개의 모델 stack\n",
    "        stack_soft = stack_models(top3)\n",
    "        \n",
    "        xgboost = create_model('xgboost')\n",
    "        stack_soft2 = stack_models(top3, meta_model=xgboost)\n",
    "        \n",
    "        # 모든 모델 중 하나의 모델 선택\n",
    "        best_model = automl(use_holdout=True)\n",
    "        pred_holdout = predict_model(best_model)\n",
    "        \n",
    "        return pred_holdout\n",
    "    \n",
    "    \n",
    "    def autokeras_model(self):\n",
    "        self.y_train = self.y_train.astype('str')\n",
    "        clf = ak.StructuredDataClassifier(overwrite=True, max_trials=5)\n",
    "        clf.fit(self.X_train, self.y_train, epochs=50)\n",
    "        predicted_y = clf.predict(self.X_test)\n",
    "        \n",
    "        return predicted_y\n",
    "    \n",
    "    def forward(self):\n",
    "        self.preprocess()\n",
    "        print(\"Model Training Start!\")\n",
    "        '''\n",
    "        각 모델들을 학습시키고 결과 비교 시작\n",
    "        \n",
    "        '''\n",
    "        pycaret_ = self.pycaret_compare_models()\n",
    "        autokeras_ = self.autokeras_model()\n",
    "        \n",
    "        pycaret_acc = accuracy_score(pycaret_['Label'], self.y_test)\n",
    "        y_test = self.y_test.astype('str')\n",
    "        autokeras_acc = accuracy_score(autokeras_, y_test)\n",
    "        \n",
    "        print(\"Accuracy for each autoML models result\")\n",
    "        print(\"Pycaret: \", pycaret_acc)\n",
    "        print(\"Autokeras: \", autokeras_acc)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b07ff8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "iris_data = np.concatenate([iris.data, iris.target.reshape(-1,1)], 1)\n",
    "df_iris = pd.DataFrame(data=iris_data, columns = iris.feature_names + ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9d81c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 05s]\n",
      "val_accuracy: 0.9166666865348816\n",
      "\n",
      "Best val_accuracy So Far: 0.9166666865348816\n",
      "Total elapsed time: 00h 00m 25s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1115 - accuracy: 0.3417\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0254 - accuracy: 0.5333\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9497 - accuracy: 0.6250\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8819 - accuracy: 0.7417\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8205 - accuracy: 0.8083\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7643 - accuracy: 0.8333\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7126 - accuracy: 0.8167\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6659 - accuracy: 0.8083\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6233 - accuracy: 0.8083\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5848 - accuracy: 0.8083\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5503 - accuracy: 0.8083\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5200 - accuracy: 0.8083\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.8167\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.8250\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.8250\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4297 - accuracy: 0.8250\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8250\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8250\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8250\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8333\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3571 - accuracy: 0.8333\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3456 - accuracy: 0.8333\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8500\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8583\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3148 - accuracy: 0.8667\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8833\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2963 - accuracy: 0.8917\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2875 - accuracy: 0.9083\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2790 - accuracy: 0.9083\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2706 - accuracy: 0.9167\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2625 - accuracy: 0.9250\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2546 - accuracy: 0.9417\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.9583\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2395 - accuracy: 0.9583\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2322 - accuracy: 0.9583\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2251 - accuracy: 0.9583\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2182 - accuracy: 0.9583\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2115 - accuracy: 0.9583\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2050 - accuracy: 0.9667\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1988 - accuracy: 0.9667\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9667\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9667\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.9667\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.9667\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1695 - accuracy: 0.9667\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1642 - accuracy: 0.9667\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1590 - accuracy: 0.9667\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1539 - accuracy: 0.9667\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.9667\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.9667\n",
      "INFO:tensorflow:Assets written to: ./structured_data_classifier/best_model/assets\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Accuracy for each autoML models result\n",
      "Pycaret:  1.0\n",
      "Autokeras:  1.0\n"
     ]
    }
   ],
   "source": [
    "clm = classification_model(df_iris)\n",
    "clm.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8d9faf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "34a0a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression_model():\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "        \n",
    "    def preprocess(self):\n",
    "        target_name = self.df.columns[-1]\n",
    "        self.exp_reg102 = setup(data = self.df, target = target_name, session_id=123,\n",
    "                  normalize = True, transformation = True, transform_target = True, \n",
    "                  combine_rare_levels = True, rare_level_threshold = 0.05,\n",
    "                  remove_multicollinearity = True, multicollinearity_threshold = 0.95,\n",
    "                  log_experiment = True, experiment_name = 'regression')\n",
    "        \n",
    "        # train / test size 를 출력\n",
    "        self.X_train = self.exp_reg102[5][1][1]\n",
    "        self.y_train = self.exp_reg102[5][2][1]\n",
    "        self.X_test = self.exp_reg102[5][3][1]\n",
    "        self.y_test = self.exp_reg102[5][4][1]\n",
    "        print('X_train_shape : ', self.X_train.shape)\n",
    "        print('y_train_shape : ', self.y_train.shape)\n",
    "        print('X_test_shape : ', self.X_test.shape)\n",
    "        print('y_test_shape : ', self.y_test.shape)\n",
    "    \n",
    "    \n",
    "    def pycaret_compare_models(self):\n",
    "        '''\n",
    "        pycaret 오픈 소스를 통한 모델 생성 및 비교\n",
    "        \n",
    "        accuracy 기준으로 10개 fold를 이용해 cross validation 성능이 가장 좋은 top 3 모델을 선정\n",
    "        \n",
    "        총 5개의 후보에 대해 비교 진행\n",
    "        1. 가장 성능이 좋은 것으로 나타난 머신러닝 모델\n",
    "        2. top 3 모델을 blending한 모델 (hard)\n",
    "        3. top 3 모델을 blending한 모델 (hard X)\n",
    "        4. top 3 모델을 stacking한 모델\n",
    "        5. top 3 모델을 xgboost를 이용해 stacking한 모델\n",
    "        \n",
    "        총 5가지 모델 중 accuracy가 가장 좋은 모델을 선정 및 결과 도출\n",
    "        '''\n",
    "        exp_reg102 = self.exp_reg102\n",
    "        top3 = compare_models(n_select=3)\n",
    "        \n",
    "        # 가장 성능이 좋은 모델 tuning\n",
    "        m1 = create_model(top3[0])\n",
    "        tuned_m1 = tune_model(m1, n_iter=50)\n",
    "        \n",
    "        m2 = create_model(top3[1])\n",
    "        m3 = create_model(top3[2])\n",
    "        \n",
    "        # 가장 성능이 좋은 3개의 모델 blend\n",
    "        blend_hard = blend_models(estimator_list = [m1, m2, m3])\n",
    "        blender_top3 = blend_models(top3)\n",
    "        \n",
    "        # 가장 성능이 좋은 3개의 모델 stack\n",
    "        stack_soft = stack_models(top3)\n",
    "        \n",
    "        xgboost = create_model('xgboost')\n",
    "        stack_soft2 = stack_models(top3, meta_model=xgboost)\n",
    "        \n",
    "        # 모든 모델 중 하나의 모델 선택\n",
    "        best_model = automl(use_holdout=True)\n",
    "        pred_holdout = predict_model(best_model)\n",
    "        \n",
    "        return pred_holdout\n",
    "\n",
    "        \n",
    "    def autokeras_model(self):\n",
    "        y_train = np.array(self.y_train)\n",
    "        clf = ak.StructuredDataRegressor(overwrite=True, max_trials=5)\n",
    "        clf.fit(self.X_train, self.y_train, epochs=50)\n",
    "        predicted_y = clf.predict(self.X_test)\n",
    "        \n",
    "        return predicted_y\n",
    "    \n",
    "    \n",
    "    def forward(self):\n",
    "        print(\"Preprocessing Start\")\n",
    "        self.preprocess()\n",
    "        print(\"Preprocessing Done!\")\n",
    "        print(\"Model Training Start!\")\n",
    "        '''\n",
    "        각 모델들을 학습시키고 결과 비교 시작\n",
    "        '''\n",
    "        pycaret_ = self.pycaret_compare_models()\n",
    "        autokeras_ = self.autokeras_model()\n",
    "        \n",
    "        pycaret_acc = mean_absolute_error(pycaret_['Label'], self.y_test)\n",
    "        y_test = self.y_test\n",
    "        autokeras_acc = mean_absolute_error(autokeras_, y_test)\n",
    "        \n",
    "        print(\"Accuracy for each autoML models result\")\n",
    "        print(\"Pycaret: \", pycaret_acc)\n",
    "        print(\"Autokeras: \", autokeras_acc)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1788de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "boston_data = np.concatenate([boston.data, boston.target.reshape(-1,1)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1e13c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boston = pd.DataFrame(boston_data, columns = list(boston.feature_names) + ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "972abb80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 04s]\n",
      "val_loss: 15.143587112426758\n",
      "\n",
      "Best val_loss So Far: 13.073578834533691\n",
      "Total elapsed time: 00h 00m 22s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 579.2468 - mean_squared_error: 579.2468\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 538.4092 - mean_squared_error: 538.4092\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 483.4941 - mean_squared_error: 483.4941\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 405.8289 - mean_squared_error: 405.8289\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 302.5171 - mean_squared_error: 302.5171\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 189.8249 - mean_squared_error: 189.8249\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 116.8722 - mean_squared_error: 116.8722\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 95.0152 - mean_squared_error: 95.0152\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 85.0840 - mean_squared_error: 85.0840\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 70.2569 - mean_squared_error: 70.2569\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 59.4530 - mean_squared_error: 59.4530\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 51.3749 - mean_squared_error: 51.3749\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 55.1013 - mean_squared_error: 55.1013\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 39.5395 - mean_squared_error: 39.5395\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 39.5356 - mean_squared_error: 39.5356\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 37.1174 - mean_squared_error: 37.1174\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 33.7307 - mean_squared_error: 33.7307\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 33.3739 - mean_squared_error: 33.3739\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 32.6368 - mean_squared_error: 32.6368\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 33.7434 - mean_squared_error: 33.7434\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 31.0141 - mean_squared_error: 31.0141\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 31.6599 - mean_squared_error: 31.6599\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.8829 - mean_squared_error: 28.8829\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.7150 - mean_squared_error: 28.7150\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 31.9253 - mean_squared_error: 31.9253\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 29.2744 - mean_squared_error: 29.2744\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.1054 - mean_squared_error: 28.1054\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.8411 - mean_squared_error: 24.8411\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.3171 - mean_squared_error: 27.3171\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.6559 - mean_squared_error: 25.6559\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.1242 - mean_squared_error: 25.1242\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.3504 - mean_squared_error: 22.3504\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.3439 - mean_squared_error: 25.3439\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.0796 - mean_squared_error: 25.0796\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.9123 - mean_squared_error: 21.9123\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.9364 - mean_squared_error: 28.9364\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.1600 - mean_squared_error: 23.1600\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.3399 - mean_squared_error: 27.3399\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.8070 - mean_squared_error: 25.8070\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.9934 - mean_squared_error: 22.9934\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.9894 - mean_squared_error: 22.9894\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.2786 - mean_squared_error: 22.2786\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.7988 - mean_squared_error: 24.7988\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.1507 - mean_squared_error: 21.1507\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.1003 - mean_squared_error: 22.1003\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.9182 - mean_squared_error: 22.9182\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.9375 - mean_squared_error: 21.9375\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.0403 - mean_squared_error: 26.0403\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.4459 - mean_squared_error: 23.4459\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 17.7277 - mean_squared_error: 17.7277\n",
      "INFO:tensorflow:Assets written to: ./structured_data_regressor/best_model/assets\n",
      "5/5 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mean_absolute_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9s/k5hgnyss19v325t2b_drb_4h0000gn/T/ipykernel_33357/2736780863.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegression_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_boston\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/9s/k5hgnyss19v325t2b_drb_4h0000gn/T/ipykernel_33357/4158243484.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mautokeras_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautokeras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mpycaret_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpycaret_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mautokeras_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautokeras_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_absolute_error' is not defined"
     ]
    }
   ],
   "source": [
    "rg = Regression_model(df_boston)\n",
    "rg.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6ec3ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_454eb_row10_col0, #T_454eb_row10_col1, #T_454eb_row10_col2, #T_454eb_row10_col3, #T_454eb_row10_col4, #T_454eb_row10_col5 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_454eb_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th class=\"col_heading level0 col2\" >RMSE</th>\n",
       "      <th class=\"col_heading level0 col3\" >R2</th>\n",
       "      <th class=\"col_heading level0 col4\" >RMSLE</th>\n",
       "      <th class=\"col_heading level0 col5\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_454eb_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_454eb_row0_col0\" class=\"data row0 col0\" >2.8407</td>\n",
       "      <td id=\"T_454eb_row0_col1\" class=\"data row0 col1\" >13.5289</td>\n",
       "      <td id=\"T_454eb_row0_col2\" class=\"data row0 col2\" >3.6782</td>\n",
       "      <td id=\"T_454eb_row0_col3\" class=\"data row0 col3\" >0.8486</td>\n",
       "      <td id=\"T_454eb_row0_col4\" class=\"data row0 col4\" >0.1392</td>\n",
       "      <td id=\"T_454eb_row0_col5\" class=\"data row0 col5\" >0.1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_454eb_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_454eb_row1_col0\" class=\"data row1 col0\" >1.6294</td>\n",
       "      <td id=\"T_454eb_row1_col1\" class=\"data row1 col1\" >4.7152</td>\n",
       "      <td id=\"T_454eb_row1_col2\" class=\"data row1 col2\" >2.1714</td>\n",
       "      <td id=\"T_454eb_row1_col3\" class=\"data row1 col3\" >0.8982</td>\n",
       "      <td id=\"T_454eb_row1_col4\" class=\"data row1 col4\" >0.1020</td>\n",
       "      <td id=\"T_454eb_row1_col5\" class=\"data row1 col5\" >0.0853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_454eb_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_454eb_row2_col0\" class=\"data row2 col0\" >1.9007</td>\n",
       "      <td id=\"T_454eb_row2_col1\" class=\"data row2 col1\" >5.9290</td>\n",
       "      <td id=\"T_454eb_row2_col2\" class=\"data row2 col2\" >2.4350</td>\n",
       "      <td id=\"T_454eb_row2_col3\" class=\"data row2 col3\" >0.9408</td>\n",
       "      <td id=\"T_454eb_row2_col4\" class=\"data row2 col4\" >0.1310</td>\n",
       "      <td id=\"T_454eb_row2_col5\" class=\"data row2 col5\" >0.1064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_454eb_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_454eb_row3_col0\" class=\"data row3 col0\" >2.5649</td>\n",
       "      <td id=\"T_454eb_row3_col1\" class=\"data row3 col1\" >17.3543</td>\n",
       "      <td id=\"T_454eb_row3_col2\" class=\"data row3 col2\" >4.1659</td>\n",
       "      <td id=\"T_454eb_row3_col3\" class=\"data row3 col3\" >0.8289</td>\n",
       "      <td id=\"T_454eb_row3_col4\" class=\"data row3 col4\" >0.1695</td>\n",
       "      <td id=\"T_454eb_row3_col5\" class=\"data row3 col5\" >0.1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_454eb_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_454eb_row4_col0\" class=\"data row4 col0\" >2.1327</td>\n",
       "      <td id=\"T_454eb_row4_col1\" class=\"data row4 col1\" >7.1562</td>\n",
       "      <td id=\"T_454eb_row4_col2\" class=\"data row4 col2\" >2.6751</td>\n",
       "      <td id=\"T_454eb_row4_col3\" class=\"data row4 col3\" >0.9393</td>\n",
       "      <td id=\"T_454eb_row4_col4\" class=\"data row4 col4\" >0.1191</td>\n",
       "      <td id=\"T_454eb_row4_col5\" class=\"data row4 col5\" >0.0996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_454eb_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_454eb_row5_col0\" class=\"data row5 col0\" >1.8943</td>\n",
       "      <td id=\"T_454eb_row5_col1\" class=\"data row5 col1\" >7.2033</td>\n",
       "      <td id=\"T_454eb_row5_col2\" class=\"data row5 col2\" >2.6839</td>\n",
       "      <td id=\"T_454eb_row5_col3\" class=\"data row5 col3\" >0.8660</td>\n",
       "      <td id=\"T_454eb_row5_col4\" class=\"data row5 col4\" >0.1308</td>\n",
       "      <td id=\"T_454eb_row5_col5\" class=\"data row5 col5\" >0.0973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_454eb_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_454eb_row6_col0\" class=\"data row6 col0\" >1.4782</td>\n",
       "      <td id=\"T_454eb_row6_col1\" class=\"data row6 col1\" >3.6572</td>\n",
       "      <td id=\"T_454eb_row6_col2\" class=\"data row6 col2\" >1.9124</td>\n",
       "      <td id=\"T_454eb_row6_col3\" class=\"data row6 col3\" >0.9458</td>\n",
       "      <td id=\"T_454eb_row6_col4\" class=\"data row6 col4\" >0.0828</td>\n",
       "      <td id=\"T_454eb_row6_col5\" class=\"data row6 col5\" >0.0667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_454eb_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_454eb_row7_col0\" class=\"data row7 col0\" >2.7817</td>\n",
       "      <td id=\"T_454eb_row7_col1\" class=\"data row7 col1\" >28.4382</td>\n",
       "      <td id=\"T_454eb_row7_col2\" class=\"data row7 col2\" >5.3327</td>\n",
       "      <td id=\"T_454eb_row7_col3\" class=\"data row7 col3\" >0.7390</td>\n",
       "      <td id=\"T_454eb_row7_col4\" class=\"data row7 col4\" >0.1929</td>\n",
       "      <td id=\"T_454eb_row7_col5\" class=\"data row7 col5\" >0.1191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_454eb_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_454eb_row8_col0\" class=\"data row8 col0\" >1.6387</td>\n",
       "      <td id=\"T_454eb_row8_col1\" class=\"data row8 col1\" >4.0674</td>\n",
       "      <td id=\"T_454eb_row8_col2\" class=\"data row8 col2\" >2.0168</td>\n",
       "      <td id=\"T_454eb_row8_col3\" class=\"data row8 col3\" >0.9273</td>\n",
       "      <td id=\"T_454eb_row8_col4\" class=\"data row8 col4\" >0.1113</td>\n",
       "      <td id=\"T_454eb_row8_col5\" class=\"data row8 col5\" >0.0917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_454eb_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_454eb_row9_col0\" class=\"data row9 col0\" >2.0260</td>\n",
       "      <td id=\"T_454eb_row9_col1\" class=\"data row9 col1\" >8.8364</td>\n",
       "      <td id=\"T_454eb_row9_col2\" class=\"data row9 col2\" >2.9726</td>\n",
       "      <td id=\"T_454eb_row9_col3\" class=\"data row9 col3\" >0.8978</td>\n",
       "      <td id=\"T_454eb_row9_col4\" class=\"data row9 col4\" >0.1286</td>\n",
       "      <td id=\"T_454eb_row9_col5\" class=\"data row9 col5\" >0.0880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_454eb_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_454eb_row10_col0\" class=\"data row10 col0\" >2.0887</td>\n",
       "      <td id=\"T_454eb_row10_col1\" class=\"data row10 col1\" >10.0886</td>\n",
       "      <td id=\"T_454eb_row10_col2\" class=\"data row10 col2\" >3.0044</td>\n",
       "      <td id=\"T_454eb_row10_col3\" class=\"data row10 col3\" >0.8832</td>\n",
       "      <td id=\"T_454eb_row10_col4\" class=\"data row10 col4\" >0.1307</td>\n",
       "      <td id=\"T_454eb_row10_col5\" class=\"data row10 col5\" >0.0990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_454eb_level0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "      <td id=\"T_454eb_row11_col0\" class=\"data row11 col0\" >0.4623</td>\n",
       "      <td id=\"T_454eb_row11_col1\" class=\"data row11 col1\" >7.3731</td>\n",
       "      <td id=\"T_454eb_row11_col2\" class=\"data row11 col2\" >1.0306</td>\n",
       "      <td id=\"T_454eb_row11_col3\" class=\"data row11 col3\" >0.0616</td>\n",
       "      <td id=\"T_454eb_row11_col4\" class=\"data row11 col4\" >0.0301</td>\n",
       "      <td id=\"T_454eb_row11_col5\" class=\"data row11 col5\" >0.0168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc4799619a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "blend_models() got an unexpected keyword argument 'method'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9s/k5hgnyss19v325t2b_drb_4h0000gn/T/ipykernel_19013/1926638769.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/9s/k5hgnyss19v325t2b_drb_4h0000gn/T/ipykernel_19013/2590364827.py\u001b[0m in \u001b[0;36mcompare_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mm3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mblend_hard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblend_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hard'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mblender_top3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblend_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: blend_models() got an unexpected keyword argument 'method'"
     ]
    }
   ],
   "source": [
    "rg.compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f643e2",
   "metadata": {},
   "source": [
    "## Autokeras\n",
    "\n",
    "- input type 에 유연한 편. ndarray, tf.data, pd.Series, pd.DataFrame 등 많은 input 지원 -> pycaret 과는 대비되는 장점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4d031ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class autokeras_classif():\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "        \n",
    "    def preprocess(self):\n",
    "        train, test = train_test_split(self.df, random_state= 123)\n",
    "        \n",
    "        self.y_train = train[train.columns[-1]]\n",
    "        self.X_train = train.drop(columns = train.columns[-1])\n",
    "        self.y_test = test[test.columns[-1]]\n",
    "        self.X_test = test.drop(columns = test.columns[-1])\n",
    "        self.y_train = self.y_train.astype('str')\n",
    "        self.y_test  = self.y_test.astype('str')\n",
    "        \n",
    "    def model_learn(self):\n",
    "        clf = ak.StructuredDataClassifier(overwrite=True, max_trials=3)\n",
    "        clf.fit(self.X_train, self.y_train, epochs=10)\n",
    "        predicted_y = clf.predict(self.X_test)\n",
    "        acc                 = accuracy_score(self.y_test, predicted_y)\n",
    "        classReport         = classification_report(self.y_test, predicted_y)\n",
    "        confMatrix          = confusion_matrix(self.y_test, predicted_y) \n",
    "\n",
    "        print(); print('Testing Results of the trained model: ')\n",
    "        print(); print('Accuracy : ', acc)\n",
    "        print(); print('Confusion Matrix :\\n', confMatrix)\n",
    "        print(); print('Classification Report :\\n',classReport)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5eb58eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "akc = autokeras_classif(df_iris)\n",
    "akc.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46acce7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 01s]\n",
      "val_accuracy: 0.875\n",
      "\n",
      "Best val_accuracy So Far: 0.875\n",
      "Total elapsed time: 00h 00m 04s\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1081 - accuracy: 0.3304\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0877 - accuracy: 0.3839\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1662 - accuracy: 0.3929\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0053 - accuracy: 0.3839\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0325 - accuracy: 0.4286\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9687 - accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9596 - accuracy: 0.4554\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9866 - accuracy: 0.4464\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9811 - accuracy: 0.4732\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8586 - accuracy: 0.5804\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "\n",
      "Testing Results of the trained model: \n",
      "\n",
      "Accuracy :  0.868421052631579\n",
      "\n",
      "Confusion Matrix :\n",
      " [[16  0  0]\n",
      " [ 3  3  2]\n",
      " [ 0  0 14]]\n",
      "\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      1.00      0.91        16\n",
      "         1.0       1.00      0.38      0.55         8\n",
      "         2.0       0.88      1.00      0.93        14\n",
      "\n",
      "    accuracy                           0.87        38\n",
      "   macro avg       0.91      0.79      0.80        38\n",
      "weighted avg       0.89      0.87      0.84        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "akc.model_learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef206648",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.16.post1\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import autokeras as ak\n",
    "print(ak.__version__)\n",
    "\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d0da82a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  target  \n",
       "0       15.3  396.90   4.98    24.0  \n",
       "1       17.8  396.90   9.14    21.6  \n",
       "2       17.8  392.83   4.03    34.7  \n",
       "3       18.7  394.63   2.94    33.4  \n",
       "4       18.7  396.90   5.33    36.2  \n",
       "..       ...     ...    ...     ...  \n",
       "501     21.0  391.99   9.67    22.4  \n",
       "502     21.0  396.90   9.08    20.6  \n",
       "503     21.0  396.90   5.64    23.9  \n",
       "504     21.0  393.45   6.48    22.0  \n",
       "505     21.0  396.90   7.88    11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6b48fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class autokeras_ref():\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "        \n",
    "    def preprocess(self):\n",
    "        train, test = train_test_split(self.df, random_state= 123)\n",
    "        \n",
    "        self.y_train = np.array(train[train.columns[-1]])\n",
    "        self.X_train = train.drop(columns = train.columns[-1])\n",
    "        self.y_test = np.array(test[test.columns[-1]])\n",
    "        self.X_test = test.drop(columns = test.columns[-1])\n",
    "        \n",
    "        \n",
    "    def model_learn(self):\n",
    "        clf = ak.StructuredDataRegressor(overwrite=True, max_trials=3)\n",
    "        clf.fit(self.X_train, self.y_train, epochs=10)\n",
    "        predicted_y = clf.predict(self.X_test)\n",
    "        print(np.mean((self.y_test-predicted_y)**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a8689cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "krg = autokeras_ref(df_boston)\n",
    "krg.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0887cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 01s]\n",
      "val_loss: 67.78148651123047\n",
      "\n",
      "Best val_loss So Far: 33.229000091552734\n",
      "Total elapsed time: 00h 00m 04s\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 589.0077 - mean_squared_error: 589.0077\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 565.5040 - mean_squared_error: 565.5040\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 533.5571 - mean_squared_error: 533.5571\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 480.6349 - mean_squared_error: 480.6349\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 393.5746 - mean_squared_error: 393.5746\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 268.0572 - mean_squared_error: 268.0572\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 148.7381 - mean_squared_error: 148.7381\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 104.0409 - mean_squared_error: 104.0409\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 81.4502 - mean_squared_error: 81.4502\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 64.4090 - mean_squared_error: 64.4090\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "135.32502765670853\n"
     ]
    }
   ],
   "source": [
    "krg.model_learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "89905eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  target  \n",
       "0       15.3  396.90   4.98    24.0  \n",
       "1       17.8  396.90   9.14    21.6  \n",
       "2       17.8  392.83   4.03    34.7  \n",
       "3       18.7  394.63   2.94    33.4  \n",
       "4       18.7  396.90   5.33    36.2  \n",
       "..       ...     ...    ...     ...  \n",
       "501     21.0  391.99   9.67    22.4  \n",
       "502     21.0  396.90   9.08    20.6  \n",
       "503     21.0  396.90   5.64    23.9  \n",
       "504     21.0  393.45   6.48    22.0  \n",
       "505     21.0  396.90   7.88    11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "05fece1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n",
      "(339, 13) (167, 13) (339,) (167,)\n"
     ]
    }
   ],
   "source": [
    "data = df_boston.values\n",
    "\n",
    "train, test = train_test_split(df_boston, random_state= 123)\n",
    "        \n",
    "data = data.astype('float32')\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "print(X.shape, y.shape)\n",
    "# separate into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e929215e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "structured_data...|True              |?                 \n",
      "structured_data...|2                 |?                 \n",
      "structured_data...|False             |?                 \n",
      "structured_data...|0                 |?                 \n",
      "structured_data...|32                |?                 \n",
      "structured_data...|32                |?                 \n",
      "regression_head...|0                 |?                 \n",
      "optimizer         |adam              |?                 \n",
      "learning_rate     |0.001             |?                 \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/keras/engine/base_preprocessing_layer.py\", line 118, in adapt_step  *\n        self.update_state(data)\n    File \"/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/keras/layers/preprocessing/index_lookup.py\", line 541, in update_state  **\n        raise ValueError(\n\n    ValueError: Cannot adapt StringLookup layer after setting a static vocabulary via init argument or `set_vocabulary`.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9s/k5hgnyss19v325t2b_drb_4h0000gn/T/ipykernel_19449/4043163094.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mak\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStructuredDataRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredicted_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/autokeras/tasks/structured_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_in_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         history = super().fit(\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/autokeras/auto_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m             )\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         history = self.tuner.search(\n\u001b[0m\u001b[1;32m    285\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/autokeras/engine/tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, epochs, callbacks, validation_split, verbose, **fit_kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         super().search(\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         )\n",
      "\u001b[0;32m/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/autokeras/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         _, history = utils.fit_with_adaptive_batch_size(\n",
      "\u001b[0;32m/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/autokeras/engine/tuner.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(model, dataset)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPreprocessingLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                 \u001b[0mtemp_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_output_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/autokeras/keras_layers.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mdata_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mencoding_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_to_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    242\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/keras/engine/base_preprocessing_layer.py\", line 118, in adapt_step  *\n        self.update_state(data)\n    File \"/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/keras/layers/preprocessing/index_lookup.py\", line 541, in update_state  **\n        raise ValueError(\n\n    ValueError: Cannot adapt StringLookup layer after setting a static vocabulary via init argument or `set_vocabulary`.\n"
     ]
    }
   ],
   "source": [
    "clff = ak.StructuredDataRegressor(overwrite=True, max_trials=3)\n",
    "clff.fit(X_train,y_train, epochs=10, batch_size = 32)\n",
    "predicted_y = clff.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5237d9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autokeras.tasks.structured_data.StructuredDataRegressor at 0x7fc6bd4bb8e0>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f876ed6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "99b04aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 2)\n",
      "(63, 1) (63,)\n",
      "(42, 1) (21, 1) (42,) (21,)\n"
     ]
    }
   ],
   "source": [
    "# load the sonar dataset\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/auto-insurance.csv'\n",
    "dataframe = read_csv(url, header=None)\n",
    "print(dataframe.shape)\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "data = data.astype('float32')\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "print(X.shape, y.shape)\n",
    "# separate into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c7130b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>392.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>46.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>15.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124</td>\n",
       "      <td>422.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>119.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>9</td>\n",
       "      <td>87.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>31</td>\n",
       "      <td>209.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>14</td>\n",
       "      <td>95.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>53</td>\n",
       "      <td>244.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>26</td>\n",
       "      <td>187.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1\n",
       "0   108  392.5\n",
       "1    19   46.2\n",
       "2    13   15.7\n",
       "3   124  422.2\n",
       "4    40  119.4\n",
       "..  ...    ...\n",
       "58    9   87.4\n",
       "59   31  209.8\n",
       "60   14   95.5\n",
       "61   53  244.6\n",
       "62   26  187.5\n",
       "\n",
       "[63 rows x 2 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "877deaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project ./structured_data_regressor/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from ./structured_data_regressor/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "search = ak.StructuredDataRegressor(max_trials=15, loss='mean_absolute_error')\n",
    "# perform the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "6bad0a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 88.3217 - mean_squared_error: 13912.2734\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 88.2879 - mean_squared_error: 13904.0801\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 88.2549 - mean_squared_error: 13896.0078\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 88.2222 - mean_squared_error: 13888.0029\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 88.1901 - mean_squared_error: 13880.2100\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 88.1579 - mean_squared_error: 13872.3984\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 88.1254 - mean_squared_error: 13864.4912\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 88.0936 - mean_squared_error: 13856.5088\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 88.0616 - mean_squared_error: 13848.4658\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 88.0293 - mean_squared_error: 13840.3662\n",
      "INFO:tensorflow:Assets written to: ./structured_data_regressor/best_model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc6a0f348b0>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(x=X_train, y=y_train, verbose=0, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "fdc56f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 117.589\n"
     ]
    }
   ],
   "source": [
    "mae, _ = search.evaluate(X_test, y_test, verbose=0)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9974806",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9s/k5hgnyss19v325t2b_drb_4h0000gn/T/ipykernel_21662/4265195184.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "929daa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ceb8c0d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9s/k5hgnyss19v325t2b_drb_4h0000gn/T/ipykernel_21963/4225672638.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6476616e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret",
   "language": "python",
   "name": "pycaret"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
