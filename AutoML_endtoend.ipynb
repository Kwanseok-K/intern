{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5b2b9b7",
   "metadata": {},
   "source": [
    "## Auto_ML\n",
    "\n",
    "### 배경\n",
    "\n",
    "    - 데이터 타입에 상관없이 특정 데이터 입력 시 자동으로 모델을 선정하고 성능을 평가하여 결과를 제시해 주는 autoML 역량 내재화를 목적으로 합니다.\n",
    "\n",
    "### 사용 가능 데이터\n",
    "\n",
    "    - 우선, table data에 대한 분석만 가능하도록 만들었으며, 추후 다양한 데이터에 대해 적용이 가능하도록 업데이트할 예정입니다.\n",
    "    \n",
    "    - Pycaret, autokeras, Tabnet 모델을 활용하며, 해당 모델을 구성하였습니다.\n",
    "    \n",
    "\n",
    "### 모델 사용 환경 및 세팅\n",
    "\n",
    "    DataFrame Input\n",
    "\n",
    "    target 변수는 마지막 column에 배치\n",
    "\n",
    "    scikit-learn version 0.23.2\n",
    "\n",
    "    tensorflow 2.5\n",
    "\n",
    "    python 3.8 사용\n",
    "\n",
    "    pycaret, autokeras\n",
    "    \n",
    "### 데이터\n",
    "\n",
    "    - 데이터는 크게 회귀를 위한 것과 분류를 위한 것으로 나뉜다.\n",
    "    \n",
    "    분류 과제에서는 scikit-laern 의 iris data를 활용해 분석을 진행했다.\n",
    "    \n",
    "    회귀 과제에서는 skckit-learn 의 boston data를 활용해 분석을 진행했다.\n",
    "    \n",
    "### 실험 세팅\n",
    "\n",
    "    - 모든 데이터에서 20 % 는 test data 로 사용하며 학습 과정에 전혀 사용하지 않고 마지막 모델들을 비교할 때만 사용하였다.\n",
    "    \n",
    "    - 각 학습 과정에서는 train data 를 train 과 valdiation으로 나누어 학습을 진행했다.\n",
    "    \n",
    "### 결과 평가\n",
    "\n",
    "    - 분류 모델에서는 Accuracy 로, 회귀 모델에서는 Mean absolute error 로 모델을 성능을 비교했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "397aa398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from tensorflow import keras\n",
    "import pycaret\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import autokeras as ak\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import mean_absolute_error, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "308cb597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e35279",
   "metadata": {},
   "outputs": [],
   "source": [
    "class classification_model():\n",
    "    \n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "        \n",
    "    def preprocess(self):\n",
    "        target_name = self.df.columns[-1]\n",
    "        \n",
    "        \n",
    "        # 학습에 사용될 dataset에 대한 transforamtion 진행 / 이 중 20% 를 test set 으로 사용하며 이는 학습에 사용되지 않음\n",
    "        self.exp_clf = setup(data = self.df, target = target_name, transformation = True, normalize = True,\n",
    "                       session_id=123, log_experiment=True, experiment_name='classification', fold_shuffle=True,\n",
    "                       imputation_type='iterative', train_size = 0.8)\n",
    "        \n",
    "        for i in self.exp_clf:\n",
    "            if isinstance(i, list):\n",
    "                if len(i) > 4:\n",
    "                    if i[0][0]=='Setup Config':\n",
    "                        #train / test size 를 출력\n",
    "                        self.X_train = i[1][1]\n",
    "                        self.y_train = i[2][1]\n",
    "                        self.X_test = i[3][1]\n",
    "                        self.y_test = i[4][1]\n",
    "                        print('X_train_shape : ', self.X_train.shape)\n",
    "                        print('y_train_shape : ', self.y_train.shape)\n",
    "                        print('X_test_shape : ', self.X_test.shape)\n",
    "                        print('y_test_shape : ', self.y_test.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def pycaret_compare_models(self):\n",
    "        '''\n",
    "        pycaret 오픈 소스를 통한 모델 생성 및 비교\n",
    "        \n",
    "        accuracy 기준으로 10개 fold를 이용해 cross validation 성능이 가장 좋은 top 3 모델을 선정\n",
    "        \n",
    "        총 5개의 후보에 대해 비교 진행\n",
    "        1. 가장 성능이 좋은 것으로 나타난 머신러닝 모델\n",
    "        2. top 3 모델을 blending한 모델 (hard)\n",
    "        3. top 3 모델을 blending한 모델 (hard X)\n",
    "        4. top 3 모델을 stacking한 모델\n",
    "        5. top 3 모델을 xgboost를 이용해 stacking한 모델\n",
    "        \n",
    "        총 5가지 모델 중 accuracy가 가장 좋은 모델을 선정 및 결과 도출\n",
    "        '''\n",
    "        exp_clf = self.exp_clf\n",
    "        top3 = compare_models(n_select=3)\n",
    "        \n",
    "        # 가장 성능이 좋은 모델 tuning\n",
    "        m1 = create_model(top3[0])\n",
    "        #tuned_model1 = tune_model(m1)\n",
    "        \n",
    "        m2 = create_model(top3[1])\n",
    "        m3 = create_model(top3[2])\n",
    "        \n",
    "        # 가장 성능이 좋은 3개의 모델 blend\n",
    "        #blend_hard = blend_models(estimator_list = [m1, m2, m3], method='hard')\n",
    "        #blender_top3 = blend_models(top3)\n",
    "        \n",
    "        # 가장 성능이 좋은 3개의 모델 stack\n",
    "        #stack_soft = stack_models(top3)\n",
    "        \n",
    "        #xgboost = create_model('xgboost')\n",
    "        #stack_soft2 = stack_models(top3, meta_model=xgboost)\n",
    "        \n",
    "        # 모든 모델 중 하나의 모델 선택\n",
    "        best_model = automl(use_holdout=True)\n",
    "        pred_holdout = predict_model(best_model)\n",
    "        \n",
    "        return pred_holdout\n",
    "    \n",
    "    \n",
    "    def autokeras_model(self):\n",
    "        self.y_train = self.y_train.astype('str')\n",
    "        clf = ak.StructuredDataClassifier(overwrite=True, max_trials=5)\n",
    "        clf.fit(self.X_train, self.y_train, epochs=50)\n",
    "        predicted_y = clf.predict(self.X_test)\n",
    "        \n",
    "        return predicted_y\n",
    "    \n",
    "    \n",
    "    def Tabnet_model(self):\n",
    "        nunique = self.X_train.nunique()\n",
    "        types = self.X_train.dtypes\n",
    "\n",
    "        categorical_columns = []\n",
    "        categorical_dims =  {}\n",
    "        for col in self.X_train.columns:\n",
    "            if types[col] == 'object' or nunique[col] < len(col)//4:\n",
    "                # print(col, df_iris[col].nunique())\n",
    "                l_enc = LabelEncoder()\n",
    "                self.X_train[col] = self.X_train[col].fillna(\"VV_likely\")\n",
    "                self.X_train[col] = l_enc.fit_transform(self.X_train[col].values)\n",
    "                self.X_test[col] = self.X_test[col].fillna(\"VV_likely\")\n",
    "                self.X_test[col] = l_enc.fit_transform(self.X_tset[col].values)\n",
    "                categorical_columns.append(col)\n",
    "                categorical_dims[col] = len(l_enc.classes_)\n",
    "            else:\n",
    "                self.X_train.fillna(self.X_train[col].mean(), inplace=True)\n",
    "                self.X_test.fillna(self.X_test[col].mean(), inplace=True)\n",
    "\n",
    "\n",
    "        # Categorical Embedding을 위해 Categorical 변수의 차원과 idxs를 담음.\n",
    "\n",
    "        features = [ col for col in self.X_train.columns] \n",
    "        cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
    "        cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(self.X_train, self.y_train, test_size = 0.2, random_state=123)\n",
    "\n",
    "        y_train = y_train.values\n",
    "        X_train = X_train.values\n",
    "\n",
    "        y_val = y_val.values\n",
    "        X_val = X_val.values\n",
    "        \n",
    "        X_test = self.X_test.values\n",
    "        \n",
    "        clf = TabNetClassifier(cat_idxs=cat_idxs,\n",
    "                       cat_dims=cat_dims,\n",
    "                       cat_emb_dim=10,\n",
    "                       optimizer_fn=torch.optim.Adam,\n",
    "                       optimizer_params=dict(lr=1e-2),\n",
    "                       scheduler_params={\"step_size\":50,\n",
    "                                         \"gamma\":0.9},\n",
    "                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                       mask_type='sparsemax' # \"sparsemax\", entmax\n",
    "                      )\n",
    "        \n",
    "        max_epochs = 30\n",
    "\n",
    "        clf.fit(\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "            eval_name=['train', 'val'],\n",
    "            eval_metric=['accuracy'],\n",
    "            max_epochs=max_epochs , patience=20,\n",
    "            batch_size=1024, virtual_batch_size=128,\n",
    "            num_workers=0,\n",
    "            weights=1,\n",
    "            drop_last=False,\n",
    "        )\n",
    "        \n",
    "        preds = clf.predict(X_test)\n",
    "        \n",
    "        return preds\n",
    "    \n",
    "    def forward(self):\n",
    "        self.preprocess()\n",
    "        print(\"Model Training Start!\")\n",
    "        '''\n",
    "        각 모델들을 학습시키고 결과 비교 시작\n",
    "        \n",
    "        '''\n",
    "        pycaret_ = self.pycaret_compare_models()\n",
    "        autokeras_ = self.autokeras_model()\n",
    "        tabnet_ = self.Tabnet_model()\n",
    "        \n",
    "        pycaret_acc = accuracy_score(pycaret_['Label'], self.y_test)\n",
    "        y_test = self.y_test.astype('str')\n",
    "        autokeras_acc = accuracy_score(autokeras_, y_test)\n",
    "        y_test_ = self.y_test.values\n",
    "        tabnet_acc = accuracy_score(tabnet_, y_test_)\n",
    "        \n",
    "        print(\"Accuracy for each autoML models result\")\n",
    "        print(\"Pycaret: \", pycaret_acc)\n",
    "        print(\"Autokeras: \", autokeras_acc)\n",
    "        print(\"Tabnet: \", tabnet_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b07ff8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "iris_data = np.concatenate([iris.data, iris.target.reshape(-1,1)], 1)\n",
    "df_iris = pd.DataFrame(data=iris_data, columns = iris.feature_names + ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d81c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_76cd6_row10_col0, #T_76cd6_row10_col1, #T_76cd6_row10_col2, #T_76cd6_row10_col3, #T_76cd6_row10_col4, #T_76cd6_row10_col5, #T_76cd6_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_76cd6_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_76cd6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_76cd6_row0_col0\" class=\"data row0 col0\" >0.9167</td>\n",
       "      <td id=\"T_76cd6_row0_col1\" class=\"data row0 col1\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row0_col2\" class=\"data row0 col2\" >0.9167</td>\n",
       "      <td id=\"T_76cd6_row0_col3\" class=\"data row0 col3\" >0.9333</td>\n",
       "      <td id=\"T_76cd6_row0_col4\" class=\"data row0 col4\" >0.9153</td>\n",
       "      <td id=\"T_76cd6_row0_col5\" class=\"data row0 col5\" >0.8750</td>\n",
       "      <td id=\"T_76cd6_row0_col6\" class=\"data row0 col6\" >0.8843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76cd6_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_76cd6_row1_col0\" class=\"data row1 col0\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row1_col1\" class=\"data row1 col1\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row1_col2\" class=\"data row1 col2\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row1_col3\" class=\"data row1 col3\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row1_col4\" class=\"data row1 col4\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row1_col5\" class=\"data row1 col5\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row1_col6\" class=\"data row1 col6\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76cd6_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_76cd6_row2_col0\" class=\"data row2 col0\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row2_col1\" class=\"data row2 col1\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row2_col2\" class=\"data row2 col2\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row2_col3\" class=\"data row2 col3\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row2_col4\" class=\"data row2 col4\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row2_col5\" class=\"data row2 col5\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row2_col6\" class=\"data row2 col6\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76cd6_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_76cd6_row3_col0\" class=\"data row3 col0\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row3_col1\" class=\"data row3 col1\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row3_col2\" class=\"data row3 col2\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row3_col3\" class=\"data row3 col3\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row3_col4\" class=\"data row3 col4\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row3_col5\" class=\"data row3 col5\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row3_col6\" class=\"data row3 col6\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76cd6_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_76cd6_row4_col0\" class=\"data row4 col0\" >0.9167</td>\n",
       "      <td id=\"T_76cd6_row4_col1\" class=\"data row4 col1\" >0.9792</td>\n",
       "      <td id=\"T_76cd6_row4_col2\" class=\"data row4 col2\" >0.9167</td>\n",
       "      <td id=\"T_76cd6_row4_col3\" class=\"data row4 col3\" >0.9333</td>\n",
       "      <td id=\"T_76cd6_row4_col4\" class=\"data row4 col4\" >0.9153</td>\n",
       "      <td id=\"T_76cd6_row4_col5\" class=\"data row4 col5\" >0.8750</td>\n",
       "      <td id=\"T_76cd6_row4_col6\" class=\"data row4 col6\" >0.8843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76cd6_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_76cd6_row5_col0\" class=\"data row5 col0\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row5_col1\" class=\"data row5 col1\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row5_col2\" class=\"data row5 col2\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row5_col3\" class=\"data row5 col3\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row5_col4\" class=\"data row5 col4\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row5_col5\" class=\"data row5 col5\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row5_col6\" class=\"data row5 col6\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76cd6_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_76cd6_row6_col0\" class=\"data row6 col0\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row6_col1\" class=\"data row6 col1\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row6_col2\" class=\"data row6 col2\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row6_col3\" class=\"data row6 col3\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row6_col4\" class=\"data row6 col4\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row6_col5\" class=\"data row6 col5\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row6_col6\" class=\"data row6 col6\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76cd6_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_76cd6_row7_col0\" class=\"data row7 col0\" >0.9167</td>\n",
       "      <td id=\"T_76cd6_row7_col1\" class=\"data row7 col1\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row7_col2\" class=\"data row7 col2\" >0.9333</td>\n",
       "      <td id=\"T_76cd6_row7_col3\" class=\"data row7 col3\" >0.9333</td>\n",
       "      <td id=\"T_76cd6_row7_col4\" class=\"data row7 col4\" >0.9167</td>\n",
       "      <td id=\"T_76cd6_row7_col5\" class=\"data row7 col5\" >0.8737</td>\n",
       "      <td id=\"T_76cd6_row7_col6\" class=\"data row7 col6\" >0.8830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76cd6_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_76cd6_row8_col0\" class=\"data row8 col0\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row8_col1\" class=\"data row8 col1\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row8_col2\" class=\"data row8 col2\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row8_col3\" class=\"data row8 col3\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row8_col4\" class=\"data row8 col4\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row8_col5\" class=\"data row8 col5\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row8_col6\" class=\"data row8 col6\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76cd6_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_76cd6_row9_col0\" class=\"data row9 col0\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row9_col1\" class=\"data row9 col1\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row9_col2\" class=\"data row9 col2\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row9_col3\" class=\"data row9 col3\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row9_col4\" class=\"data row9 col4\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row9_col5\" class=\"data row9 col5\" >1.0000</td>\n",
       "      <td id=\"T_76cd6_row9_col6\" class=\"data row9 col6\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76cd6_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_76cd6_row10_col0\" class=\"data row10 col0\" >0.9750</td>\n",
       "      <td id=\"T_76cd6_row10_col1\" class=\"data row10 col1\" >0.9979</td>\n",
       "      <td id=\"T_76cd6_row10_col2\" class=\"data row10 col2\" >0.9767</td>\n",
       "      <td id=\"T_76cd6_row10_col3\" class=\"data row10 col3\" >0.9800</td>\n",
       "      <td id=\"T_76cd6_row10_col4\" class=\"data row10 col4\" >0.9747</td>\n",
       "      <td id=\"T_76cd6_row10_col5\" class=\"data row10 col5\" >0.9624</td>\n",
       "      <td id=\"T_76cd6_row10_col6\" class=\"data row10 col6\" >0.9651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76cd6_level0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "      <td id=\"T_76cd6_row11_col0\" class=\"data row11 col0\" >0.0382</td>\n",
       "      <td id=\"T_76cd6_row11_col1\" class=\"data row11 col1\" >0.0063</td>\n",
       "      <td id=\"T_76cd6_row11_col2\" class=\"data row11 col2\" >0.0359</td>\n",
       "      <td id=\"T_76cd6_row11_col3\" class=\"data row11 col3\" >0.0306</td>\n",
       "      <td id=\"T_76cd6_row11_col4\" class=\"data row11 col4\" >0.0386</td>\n",
       "      <td id=\"T_76cd6_row11_col5\" class=\"data row11 col5\" >0.0575</td>\n",
       "      <td id=\"T_76cd6_row11_col6\" class=\"data row11 col6\" >0.0532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd8a655ed00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clm = classification_model(df_iris)\n",
    "clm.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9faf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a0a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression_model():\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "        \n",
    "    def preprocess(self):\n",
    "        target_name = self.df.columns[-1]\n",
    "        self.exp_reg102 = setup(data = self.df, target = target_name, session_id=123,\n",
    "                  normalize = True, transformation = True, transform_target = True, \n",
    "                  combine_rare_levels = True, rare_level_threshold = 0.05,\n",
    "                  remove_multicollinearity = True, multicollinearity_threshold = 0.95,\n",
    "                  log_experiment = True, experiment_name = 'regression')\n",
    "        \n",
    "        for i in self.exp_reg102:\n",
    "            if isinstance(i, list):\n",
    "                if len(i) > 4:\n",
    "                    if i[0][0]=='Setup Config':\n",
    "                        #train / test size 를 출력\n",
    "                        self.X_train = i[1][1]\n",
    "                        self.y_train = i[2][1]\n",
    "                        self.X_test = i[3][1]\n",
    "                        self.y_test = i[4][1]\n",
    "                        print('X_train_shape : ', self.X_train.shape)\n",
    "                        print('y_train_shape : ', self.y_train.shape)\n",
    "                        print('X_test_shape : ', self.X_test.shape)\n",
    "                        print('y_test_shape : ', self.y_test.shape)\n",
    "    \n",
    "    \n",
    "    def pycaret_compare_models(self):\n",
    "        '''\n",
    "        pycaret 오픈 소스를 통한 모델 생성 및 비교\n",
    "        \n",
    "        accuracy 기준으로 10개 fold를 이용해 cross validation 성능이 가장 좋은 top 3 모델을 선정\n",
    "        \n",
    "        총 5개의 후보에 대해 비교 진행\n",
    "        1. 가장 성능이 좋은 것으로 나타난 머신러닝 모델\n",
    "        2. top 3 모델을 blending한 모델 (hard)\n",
    "        3. top 3 모델을 blending한 모델 (hard X)\n",
    "        4. top 3 모델을 stacking한 모델\n",
    "        5. top 3 모델을 xgboost를 이용해 stacking한 모델\n",
    "        \n",
    "        총 5가지 모델 중 accuracy가 가장 좋은 모델을 선정 및 결과 도출\n",
    "        '''\n",
    "        exp_reg102 = self.exp_reg102\n",
    "        top3 = compare_models(n_select=3)\n",
    "        \n",
    "        # 가장 성능이 좋은 모델 tuning\n",
    "        m1 = create_model(top3[0])\n",
    "        tuned_m1 = tune_model(m1, n_iter=50)\n",
    "        \n",
    "        m2 = create_model(top3[1])\n",
    "        m3 = create_model(top3[2])\n",
    "        \n",
    "        # 가장 성능이 좋은 3개의 모델 blend\n",
    "        #blend_hard = blend_models(estimator_list = [m1, m2, m3])\n",
    "        #blender_top3 = blend_models(top3)\n",
    "        \n",
    "        # 가장 성능이 좋은 3개의 모델 stack\n",
    "        #stack_soft = stack_models(top3)\n",
    "        \n",
    "        #xgboost = create_model('xgboost')\n",
    "        #stack_soft2 = stack_models(top3, meta_model=xgboost)\n",
    "        \n",
    "        # 모든 모델 중 하나의 모델 선택\n",
    "        best_model = automl(use_holdout=True)\n",
    "        pred_holdout = predict_model(best_model)\n",
    "        \n",
    "        return pred_holdout\n",
    "\n",
    "        \n",
    "    def autokeras_model(self):\n",
    "        y_train = np.array(self.y_train)\n",
    "        clf = ak.StructuredDataRegressor(overwrite=True, max_trials=5)\n",
    "        clf.fit(self.X_train, self.y_train, epochs=50)\n",
    "        predicted_y = clf.predict(self.X_test)\n",
    "        \n",
    "        return predicted_y\n",
    "   \n",
    "    def Tabnet_model(self):\n",
    "        nunique = self.X_train.nunique()\n",
    "        types = self.X_train.dtypes\n",
    "\n",
    "        categorical_columns = []\n",
    "        categorical_dims =  {}\n",
    "        for col in self.X_train.columns:\n",
    "            if types[col] == 'object' or nunique[col] < len(col)//4:\n",
    "                # print(col, df_iris[col].nunique())\n",
    "                l_enc = LabelEncoder()\n",
    "                self.X_train[col] = self.X_train[col].fillna(\"VV_likely\")\n",
    "                self.X_train[col] = l_enc.fit_transform(self.X_train[col].values)\n",
    "                self.X_test[col] = self.X_test[col].fillna(\"VV_likely\")\n",
    "                self.X_test[col] = l_enc.fit_transform(self.X_tset[col].values)\n",
    "                categorical_columns.append(col)\n",
    "                categorical_dims[col] = len(l_enc.classes_)\n",
    "            else:\n",
    "                self.X_train.fillna(self.X_train[col].mean(), inplace=True)\n",
    "                self.X_test.fillna(self.X_test[col].mean(), inplace=True)\n",
    "\n",
    "\n",
    "        # Categorical Embedding을 위해 Categorical 변수의 차원과 idxs를 담음.\n",
    "\n",
    "        features = [ col for col in self.X_train.columns] \n",
    "        cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
    "        cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(self.X_train, self.y_train, test_size = 0.2, random_state=123)\n",
    "\n",
    "        y_train = y_train.values.reshape(-1,1)\n",
    "        X_train = np.array(X_train.values)\n",
    "\n",
    "        y_val = y_val.values.reshape(-1,1)\n",
    "        X_val = np.array(X_val.values)\n",
    "        \n",
    "        X_test = np.array(self.X_test.values)\n",
    "        \n",
    "        clf = TabNetRegressor(cat_idxs=cat_idxs,\n",
    "                       cat_dims=cat_dims,\n",
    "                       cat_emb_dim=10,\n",
    "                       optimizer_fn=torch.optim.Adam,\n",
    "                       optimizer_params=dict(lr=1e-2),\n",
    "                       scheduler_params={\"step_size\":50,\n",
    "                                         \"gamma\":0.9},\n",
    "                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                       mask_type='sparsemax' # \"sparsemax\", entmax\n",
    "                      )\n",
    "        \n",
    "        max_epochs = 30\n",
    "\n",
    "        clf.fit(\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "            eval_name=['train', 'val'],\n",
    "            eval_metric=['mae'],\n",
    "            max_epochs=max_epochs , patience=20,\n",
    "            batch_size=1024, virtual_batch_size=128,\n",
    "            num_workers=0,\n",
    "            drop_last=False,\n",
    "        )\n",
    "        \n",
    "        preds = clf.predict(X_test)\n",
    "        \n",
    "        return preds\n",
    "        \n",
    "    \n",
    "    def forward(self):\n",
    "        print(\"Preprocessing Start\")\n",
    "        self.preprocess()\n",
    "        print(\"Preprocessing Done!\")\n",
    "        print(\"Model Training Start!\")\n",
    "        '''\n",
    "        각 모델들을 학습시키고 결과 비교 시작\n",
    "        '''\n",
    "        pycaret_ = self.pycaret_compare_models()\n",
    "        autokeras_ = self.autokeras_model()\n",
    "        tabnet_ = self.Tabnet_model()\n",
    "        \n",
    "        pycaret_mae = mean_absolute_error(pycaret_['Label'], self.y_test)\n",
    "        y_test = self.y_test\n",
    "        autokeras_mae = mean_absolute_error(autokeras_, y_test)\n",
    "        tabnet_mae = mean_absolute_error(tabnet_, y_test)\n",
    "        \n",
    "        print(\"Mean absolute error for each autoML models result\")\n",
    "        print(\"Pycaret: \", pycaret_mae)\n",
    "        print(\"Autokeras: \", autokeras_mae)\n",
    "        print(\"Tabnet: \", tabnet_mae)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1788de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "boston_data = np.concatenate([boston.data, boston.target.reshape(-1,1)], 1)\n",
    "df_boston = pd.DataFrame(boston_data, columns = list(boston.feature_names) + ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972abb80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rg = Regression_model(df_boston)\n",
    "rg.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a9eb60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret",
   "language": "python",
   "name": "pycaret"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
